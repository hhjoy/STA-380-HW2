---
title: "STA S380 HW2"
author: "Hope Knopf"
date: "8/17/2018"
output: html_document
---
###Flights at ABIA
```{r}
library(tm)


```

###Author Attribution
```{r}
readerPlain = function(fname){
  readPlain(elem=list(content=readLines(fname)), 
            id=fname, language='en') }
author_dirs = Sys.glob("/Users/hopeknopf/Desktop/STA 380-master/data/ReutersC50/*")

file_list = NULL
labels = NULL
for(author in author_dirs) {
  author_name = substring(author, first=84)
  files_to_add = Sys.glob(paste0(author, '/*.txt'))
  file_list = append(file_list, files_to_add)
  labels = append(labels, rep(author_name, length(files_to_add)))
}

all_docs = lapply(file_list, readerPlain) 
names(all_docs) = file_list
names(all_docs) = sub('.txt', '', names(all_docs))

train_corpus = Corpus(VectorSource(all_docs))
names(train_corpus) = file_list


train_corpus = tm_map(train_corpus, content_transformer(tolower))
train_corpus = tm_map(train_corpus, content_transformer(removeNumbers))
train_corpus = tm_map(train_corpus, content_transformer(removePunctuation))
train_corpus = tm_map(train_corpus, content_transformer(stripWhitespace))
train_corpus = tm_map(train_corpus, content_transformer(removeWords), stopwords("en"))

DTM_train = DocumentTermMatrix(train_corpus)
DTM_train = removeSparseTerms(DTM_train, .99)
DTM_train

X_train = as.matrix(DTM_train)

smooth_count = 1/nrow(X_train)
w_all = rowsum(X_train + smooth_count, labels)
w_all = w_all/sum(w_all)
w_all = log(w_all)


#run on test data
author_dirs = Sys.glob("/Users/hopeknopf/Desktop/STA 380-master/data/ReutersC50/*")

file_list = NULL
test_labels = NULL
author_names = NULL
for(author in author_dirs) {
  author_name = substring(author, first=83)
  author_names = append(author_names, author_name)
  files_to_add = Sys.glob(paste0(author, '/*.txt'))
  file_list = append(file_list, files_to_add)
  test_labels = append(test_labels, rep(author_name, length(files_to_add)))
}

all_docs = lapply(file_list, readerPlain) 
names(all_docs) = file_list
names(all_docs) = sub('.txt', '', names(all_docs))

test_corpus = Corpus(VectorSource(all_docs))
names(test_corpus) = file_list

test_corpus = tm_map(test_corpus, content_transformer(tolower))
test_corpus = tm_map(test_corpus, content_transformer(removeNumbers))
test_corpus = tm_map(test_corpus, content_transformer(removePunctuation))
test_corpus = tm_map(test_corpus, content_transformer(stripWhitespace))
test_corpus = tm_map(test_corpus, content_transformer(removeWords), stopwords("en"))

DTM_test = DocumentTermMatrix(test_corpus, list(dictionary=colnames(DTM_train)))
DTM_test

 
X_train = as.matrix(DTM_train)

smooth_count = 1/nrow(X_train)
w_all = rowsum(X_train + smooth_count, labels)
w_all = w_all/sum(w_all)
w_all = log(w_all)
  
#run Naive Bayes
X_test = as.matrix(DTM_test)
predictions = NULL
for (i in 1:nrow(X_test)) {
  # get maximum Naive Bayes log probabilities
  max = -(Inf)
  author = NULL
  for (j in 1:nrow(w_all)) {
    result = sum(w_all[j,]*X_test[i,])
    if (result > max) {
      max = result
      author = rownames(w_all)[j]
    }
  }
  predictions = append(predictions, author)
}

predict_results = table(test_labels,predictions)

```



###Practice with Association Rule Mining
```{r}
library(arules)
library(arulesViz)

groceries = read.transactions("/Users/hopeknopf/Desktop/STA 380 part 2/groceries.txt", format = 'basket', sep = ',')
summary(groceries)

groceries_rules = apriori(groceries, parameter=list(support=.005, confidence=.5, maxlen=8))
inspect(groceries_rules)

inspect(subset(groceries_rules, subset=lift > 3))
inspect(subset(groceries_rules, subset=confidence > 0.6))
inspect(subset(groceries_rules, subset=lift > 3 & confidence > 0.6))

plot(groceries_rules)
```

A lot of the item sets are very similar products grouped together, like citrus fruit and tropical fruit or root vegetables and other vegetables. The highest lift values were primarily sets of items that inform the purchase of 'other vegetables.'  We chose a threshhold for lift of 3, because most of the lift values ranged from 1-3, so the values with lift >3 showed us the highly informative baskets.  Most of the confidence values ranged from 0.5-0.7 so we chose a threshhold of confidence > 0.6.  The rules we found made sense, and primarily tell us about what groups of items tell us about the liklihood of buying whole milk and vegetables.  