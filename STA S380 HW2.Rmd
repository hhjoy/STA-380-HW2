---
title: "STA S380 HW2"
author: "Hope Knopf"
date: "8/17/2018"
output: html_document
---
###Flights at ABIA
```{r message=FALSE, warning=FALSE}
library(tm)
setwd('/users/chelseamatthews/Documents')
airlinedata = read.csv('ABIA.csv', header=TRUE)

#percentage of flights cancelled for each airline
dfcancelled = data.frame(aggregate(airlinedata$Cancelled~airlinedata$UniqueCarrier,airlinedata,sum))

df=data.frame(aggregate(airlinedata$FlightNum ~ airlinedata$UniqueCarrier,airlinedata, length))
finaldf = merge(dfcancelled,df)
finaldf = within(finaldf, percent <- airlinedata.Cancelled/airlinedata.FlightNum)
finaldf = finaldf[order(finaldf$percent),]

barplot(finaldf$percent, names = finaldf$arrivaldelays.UniqueCarrier,
        xlab = 'Unique Carrier', ylab = '% of Flights Cancelled',
        main = "% of Flights Cancelled per Airline",las=2, space = .5, col = 'dodgerblue3',
        names.arg = c("NW","F9","US","WN","XE","UA","DL","CO","YV","B6", "OO","EV","OH","9E","AA","MQ"))

```
American Eagle (MQ) had the highest percentage of cancelled flights. American Airlines (AA) had the next highest percent of cancelled flights. 

#Arrivals

```{r message=FALSE, warning=FALSE}
#average arrival delay

arrdelay = airlinedata[which(airlinedata[,15]>0),]
df_arrdelay = data.frame(aggregate(arrdelay$ArrDelay ~ arrdelay$UniqueCarrier,arrdelay,mean))
df_arrdelay = df_arrdelay[order(df_arrdelay$arrdelay.ArrDelay),]

barplot(df_arrdelay$arrdelay.ArrDelay, names = df_arrdelay$arrdelay.UniqueCarrier,
        xlab = "Unique Carrier", ylab = "Avg. Arrival Delays (minutes)",
        main = "Avg. Arrival Delay times per Airline", las = 2, space=.5, col = 'darkseagreen')
```
JetBlue(B6) has the longest average arrival delays, followed by ExpressJet (EV) and Mesa Airlines(YV). 

```{r}
#arrival delays per month
df_arrdelaymon = data.frame(aggregate(arrdelay$ArrDelay ~ arrdelay$Month,arrdelay,length))
plot(df_arrdelaymon$arrdelay.Month, df_arrdelaymon$arrdelay.ArrDelay, 
     xlab = "Month", ylab = "# of Arrival Delays", 
     main = "Number of Arrival delays per month", type ='o', col='lightblue',lwd=2, pch=10)
```
March and June had the highest number of arrival delays, while September and November had the smallest number of arrival delays. 

```{r message=FALSE, warning=FALSE}
#average arrival delays per month
df_arrdelaymon = data.frame(aggregate(arrdelay$ArrDelay ~ arrdelay$Month,arrdelay,mean))
plot(df_arrdelaymon$arrdelay.Month, df_arrdelaymon$arrdelay.ArrDelay, 
     xlab = "Month", ylab = "Avg. Arrival Delay (Minutes)", 
     main = "Avg. Arrival delays per month", type ='o', col='lightblue',lwd=2, pch=10)
```
September, October and November had the shortest average arrival delays, while December had the longest. 

```{r message=FALSE, warning=FALSE}
#arrival delays by day of the week

df_arrdelayday = data.frame(aggregate(arrdelay$ArrDelay ~ arrdelay$DayOfWeek,arrdelay,length))

plot(df_arrdelayday$arrdelay.DayOfWeek, df_arrdelayday$arrdelay.ArrDelay, 
     xlab = "Day of Week (1-Monday - 7-Sunday)", ylab = "# of Arrival Delays", 
     main = "Number of Arrival delays by Day of Week", type ='o', col='thistle',lwd=2, pch=10)
```
Saturdays had the lowest amount of arrival delays, while Thursdays and Fridays had the most. 

```{r}
#average time of arrival delays by day of the week

df_arrdelayday = data.frame(aggregate(arrdelay$ArrDelay ~ arrdelay$DayOfWeek,arrdelay,mean))

plot(df_arrdelayday$arrdelay.DayOfWeek, df_arrdelayday$arrdelay.ArrDelay, 
     xlab = "Day of Week (1-Monday - 7-Sunday", ylab = "Average Time of Arr Delay (minutes)", 
     main = "Avg. Time of  Arrival Delay by Day of Week", type ='o', col='steelblue',lwd=2, pch=10)
```
The Average time of arrival delays is the lowest on Wednesdays and highest on Sundays. 

#average time of arrival delays by time of day

```{r message=FALSE, warning=FALSE}
#average time of arrival delays by time of day

df_arrdelaytime = data.frame(aggregate(arrdelay$ArrDelay ~ arrdelay$ArrTime,arrdelay,length))

plot(df_arrdelaytime$arrdelay.ArrTime, df_arrdelaytime$arrdelay.ArrDelay, 
     xlab = "Time of Day (24 Hour Time)", ylab = "# of Arr. Delay ", 
     main = "Number of Arrival Delay by Time of Day", type ='o', col='slategray',lwd=2, pch=10)
```
Between 1 am and 6 am there are the fewest amount of arrival delays. This is probably due to the lesser amount of flights during this time, since many airports don't have flights bewtween 2 am and 5 am . Around 11 am and 8 pm seem to ahve the the highest number of arrival delays. The best time for arrivals seems to be from around 6 am to 8 am. The number stays pretty consistent throughout the day after 10 am. 

```{r}
#average time of arrival delays by time of day

df_arrdelaytime = data.frame(aggregate(arrdelay$ArrDelay ~ arrdelay$ArrTime,arrdelay,mean))

plot(df_arrdelaytime$arrdelay.ArrTime, df_arrdelaytime$arrdelay.ArrDelay, 
     xlab = "Time of Day (24 Hour Time)", ylab = "Average Time of Arr Delay (minutes)", 
     main = "Avg. Time of  Arrival Delay by Time of Day", type ='o', col='slategray',lwd=2, pch=10)
```
Between Midnight and 5 am the average time of arrival delay is the highest (with a peak at around 5:30am). After about 6 am, average arrival delay by time of day is pretty low. 

#Departures

```{r}
#average departure delay 

depdelay = airlinedata[which(airlinedata[,16]>0),]
df_depdelay = data.frame(aggregate(depdelay$DepDelay ~ depdelay$UniqueCarrier,depdelay,mean))
df_depdelay = df_depdelay[order(df_depdelay$depdelay.DepDelay),]

barplot(df_depdelay$depdelay.DepDelay, names = df_depdelay$depdelay.UniqueCarrier,
        xlab = "Unique Carrier", ylab = "Avg. Departure Delays (minutes)",
        main = "Avg. Departure Delay times per Airline", las = 2, space=.5, col = 'orange3')
```
Departure delays are usually linked to arrival delays. Looking at departure delays is more important in understanding the likelihood of arriving at your destination on time/ or making conncections at another airport.  The top three airlines with the longest departure delay times were Mesa Airlines (YV), PSA Airlines (OH), and Jet Blue(B6). The airlines with the longest delayed departure times is similar to the airlines with the longest avergae arrival delays. 

```{r}
#% of of departures delayed per airline 

df_delay_percent = data.frame(aggregate(depdelay$DepDelay ~ depdelay$UniqueCarrier, 
                                        depdelay, length))
df_percent = data.frame(aggregate(airlinedata$FlightNum ~ airlinedata$UniqueCarrier, 
                                  airlinedata, length))

percent_finaldf = merge(df_delay_percent, df_percent, by.x="depdelay.UniqueCarrier", by.y="airlinedata.UniqueCarrier")
percent_finaldf = within(percent_finaldf, percent <- depdelay.DepDelay/airlinedata.FlightNum)
percent_finaldf = percent_finaldf[order(percent_finaldf$percent),]
barplot(percent_finaldf$percent, names = percent_finaldf$depdelay.UniqueCarrier,
        xlab = "Unique Carrier", ylab = "% of Depatures Delayed",
        main = "% of Departures Delayed per Airline", las=2, space=.5, col='lightcyan2')
```
Looking at the % of Departures delayed per Airline, ExpressJet(EV) has 50% of flights delayed. Southwest (WN) also has close to 50% of flights delayed. The three airlines with the highest % of departures delayed (EpressJet, Southwest and Continential Airlines) are not the same airlines with the highest average  departure delay times. This means that while one might have longer average departure delays, it does not mean they are delayed the most. 

```{r}
#departure delays per month
df_depdelaymon = data.frame(aggregate(depdelay$DepDelay ~ depdelay$Month,depdelay,length))
plot(df_depdelaymon$depdelay.Month, df_depdelaymon$depdelay.DepDelay, 
     xlab = "Month", ylab = "# of Departure Delays", 
     main = "Number of Departure delays per month", type ='o', col='sienna',lwd=2, pch=10)
```
The highest number of departure delays occur in March and June. The months with the least amount of departure delays were September and November. Next, we will look at which months had the longest average delays. 

```{r}
#average departure delays per month
dfmm =data.frame(aggregate(depdelay$DepDelay~depdelay$Month, depdelay,mean))

plot(dfmm$depdelay.Month, dfmm$depdelay.DepDelay, 
     xlab = "Month", ylab="Avg. Departure Delays (Minutes)", 
     main = "Avg. Departure Delay times by Month", type='o',
     col = 'palegreen',lwd=2, pch =10)
```
While March and June had highest number of delays. December had the longest average delays. September and October had the shortest average departure delays. 

```{r}
#deprture delays by day of the week

df_depdelayday = data.frame(aggregate(depdelay$DepDelay ~ depdelay$DayOfWeek,depdelay,length))

plot(df_depdelayday$depdelay.DayOfWeek, df_depdelayday$depdelay.DepDelay, 
     xlab = "Day of Week (1-Monday - 7-Sunday)", ylab = "# of Departure Delays", 
     main = "Number of Departure delays by Day of Week", type ='o', col='tomato',lwd=2, pch=10)
```
Fridays have the most number of Departure delays, followed by Thursdays. Saturdays had the lowest number of departure delays. 

```{r}
#average departure delays by day of the  week

df_depdelayday = data.frame(aggregate(depdelay$DepDelay ~ depdelay$DayOfWeek,depdelay,mean))

plot(df_depdelayday$depdelay.DayOfWeek, df_depdelayday$depdelay.DepDelay, 
     xlab = "Day of Week (1-Monday - 7-Sunday)", ylab = "Avg. Departure Delays (minutes)", 
     main = "Avg.  Departure delays by Day of Week", type ='o', col='royalblue',lwd=2, pch=10)
```
Wednesdays had the shortest average time of departure delays, while Sunday had the longest delays. Tuesdays had the second longest average departure delays. 

```{r}
#average time of departure delays by time of day

df_depdelaytime = data.frame(aggregate(depdelay$DepDelay ~ depdelay$DepTime,depdelay,length))

plot(df_depdelaytime$depdelay.DepTime, df_depdelaytime$depdelay.DepDelay, 
     xlab = "Time of Day (24 Hour Time)", ylab = "# of Dep. Delay ", 
     main = "Number of Departure Delays by Hour", type ='o', col='rosybrown',lwd=2, pch=10)
```
It seems like the most delayed happen in the middle of the day between 6 am and 8 pm. There a re a coupleof peaks between 6 am and 7 pm. After 8pm, there are less departure delays and between midnight and 5 am there are almost zero. But, then again there are not many departing flights between midnight and 5 am. 

```{r}
#average time of departure delays by time of day

df_depdelaytime = data.frame(aggregate(depdelay$DepDelay ~ depdelay$DepTime,depdelay,mean))


plot(df_depdelaytime$depdelay.DepTime, df_depdelaytime$depdelay.DepDelay, 
     xlab = "Time of Day (24 Hour Time)", ylab = "Avg. Departure Delays (Minutes) ", 
     main = "Avg. Time of Departure Delays by Hour", type ='o', col='rosybrown',lwd=2, pch=10)
```
While there are not many departure delays between midnight and 5 am, the ones that do occur are long delays. In contrast the delays during the peak delay times seem to be shorts. The night delays (after 8pm) are longer, but not as long as the early morning delays. 

#Destinations and Origins
```{r}
departures = subset(airlinedata, Origin == 'AUS')

#average departure delay by destination 
departdelay = departures[which(departures[,16]>0),]
df_depdelays = data.frame(aggregate(departdelay$DepDelay ~ departdelay$Dest, departdelay, mean))
df_depdelays2 = df_depdelays[order(-df_depdelays$departdelay.DepDelay),][1:15,]

barplot(df_depdelays2$departdelay.DepDelay, names = df_depdelays2$departdelay.Dest,xlab = "Destination", ylab = 'Avg. Departure Delays (minutes)', main = 'Longest Avg. Departure Delay times by Destination', las =2, space=.5, col='plum2')
```
The above graph shows which airports are the destinations in which there are the longest average delays. The longest delays happen for flights headed to Des Moines, Iowa (DSM). THe second longest are for St. Louis (STL) and the third longest delays are for flights headed to Newark, NJ (EWR). 

```{r}
#destinations with the shortest average delays

departures = subset(airlinedata, Origin == 'AUS')

#average departure delay by destination 
departdelay = departures[which(departures[,16]>0),]
df_depdelays = data.frame(aggregate(departdelay$DepDelay ~ departdelay$Dest, departdelay, mean))
df_depdelays2 = df_depdelays[order(df_depdelays$departdelay.DepDelay),][1:15,]

barplot(df_depdelays2$departdelay.DepDelay, names = df_depdelays2$departdelay.Dest,xlab = "Destination", ylab = 'Avg. Departure Delays (minutes)', main = ' Shortest Avg. Departure Delay times by Destination', las =2, space=.5, col='lavender')
```
The three destinations with the shortest average departure delays are San Diego (SAN), Tucson (TUS) and Valley International Airport (HRL). 

```{r}
#average arrival delay by Origin
arrivals = subset(airlinedata, Origin != 'AUS')
arrivedelay = arrivals[which(arrivals[,15]>0),]
df_arrdelays = data.frame(aggregate(arrivedelay$ArrDelay ~ arrivedelay$Origin, arrivedelay, mean))
df_arrdelays2 = df_arrdelays[order(-df_arrdelays$arrivedelay.ArrDelay), ][1:15,]

barplot(df_arrdelays2$arrivedelay.ArrDelay, names = df_arrdelays2$arrivedelay.Origin,xlab = "Origin", ylab = 'Avg. Arrival Delays (minutes)', main = 'Longest Avg. Arrival Delay times by Origin', las =2, space=.5, col='lightsteelblue')
```
The longest average arrival delays happens with planes coming from McGhee Tyson Airport in Knoxville, TN (TYS), Will Rogers World Airport in Oklahoma City, and Philadelphia (PHL). 

```{r}
#average shortest arrival delay by Origin
arrivals = subset(airlinedata, Origin != 'AUS')
arrivedelay = arrivals[which(arrivals[,15]>0),]
df_arrdelays = data.frame(aggregate(arrivedelay$ArrDelay ~ arrivedelay$Origin, arrivedelay, mean))
df_arrdelays2 = df_arrdelays[order(df_arrdelays$arrivedelay.ArrDelay), ][1:15,]

barplot(df_arrdelays2$arrivedelay.ArrDelay, names = df_arrdelays2$arrivedelay.Origin,xlab = "Origin", ylab = 'Avg. Arrival Delays (minutes)', main = 'Shortest Avg. Arrival Delay times by Origin', las =2, space=.5, col='lightsteelblue')

```

The shorest average arrival delays happen with planes coming from Oakland, California (OAK), Tampa, Florida (TPA) and Valley International (HRL). 

###Author Attribution
```{r}
library(tm) 

readerPlain = function(fname){
				readPlain(elem=list(content=readLines(fname)), 
							id=fname, language='en') }

author_dirs = Sys.glob('~/Documents/UT/Summer Classes/Intro to Predictive Modeling/Part 2/HW 2/ReutersC50/C50train/*') 

file_list = NULL
labels = NULL
for(author in author_dirs) {
  author_name = substring(author, first=84)
  files_to_add = Sys.glob(paste0(author, '/*.txt'))
  file_list = append(file_list, files_to_add)
  labels = append(labels, rep(author_name, length(files_to_add)))
}

#clean up file names
mynames = file_list %>% #trying to clean up file nammes
	 { strsplit(., '/', fixed=TRUE) } %>% #split on /
	 { lapply(., tail, n=2) } %>%
	 { lapply(., paste0, collapse = '') } %>%
	 unlist

# Rename the articles
docs = lapply(file_list, readerPlain) #grabs all text files in directory
mynames
names(docs) = mynames

#creat corpus
documents_raw = Corpus(VectorSource(docs)) 

my_documents = documents_raw
my_documents = tm_map(my_documents, content_transformer(tolower)) # make everything lowercase, tm_map takes a corpus and a function
my_documents = tm_map(my_documents, content_transformer(removeNumbers)) # remove numbers
my_documents = tm_map(my_documents, content_transformer(removePunctuation)) # remove punctuation
my_documents = tm_map(my_documents, content_transformer(stripWhitespace)) ## remove excess white-space
my_documents = tm_map(my_documents, content_transformer(removeWords), stopwords("en")) #remove stop words

DTM_train = DocumentTermMatrix(my_documents)
DTM_train = removeSparseTerms(DTM_train, 0.99) #pass corpus and threshold

X_train = as.matrix(DTM_train)

smooth_count = 1/nrow(X_train)
w_all = rowsum(X_train + smooth_count, labels) #prob of all words
w_all = w_all/sum(w_all)
w_all = log(w_all)
```

```{r}
#Do same for test

author_dirs = Sys.glob('~/Documents/UT/Summer Classes/Intro to Predictive Modeling/Part 2/HW 2/ReutersC50/C50test/*') 

file_list = NULL
test_labels = NULL
author_names = NULL
for(author in author_dirs) {
  author_name = substring(author, first=83)
  author_names = append(author_names, author_name)
  files_to_add = Sys.glob(paste0(author, '/*.txt'))
  file_list = append(file_list, files_to_add)
  test_labels = append(test_labels, rep(author_name, length(files_to_add)))
}


#clean up file names
mynames = file_list %>% #trying to clean up file nammes
  { strsplit(., '/', fixed=TRUE) } %>% #split on /
  { lapply(., tail, n=2) } %>%
  { lapply(., paste0, collapse = '') } %>%
  unlist

# Rename the articles
docs = lapply(file_list, readerPlain) #grabs all text files in directory
mynames
names(docs) = mynames

#creat corpus
documents_raw_test = Corpus(VectorSource(docs)) 

my_documents_test = documents_raw_test
my_documents_test = tm_map(my_documents_test, content_transformer(tolower)) # make everything lowercase, tm_map takes a corpus and a function
my_documents_test = tm_map(my_documents_test, content_transformer(removeNumbers)) # remove numbers
my_documents_test = tm_map(my_documents_test, content_transformer(removePunctuation)) # remove punctuation
my_documents_test = tm_map(my_documents_test, content_transformer(stripWhitespace)) ## remove excess white-space
my_documents_test = tm_map(my_documents_test, content_transformer(removeWords), stopwords("en")) #remove stop words

DTM_test = DocumentTermMatrix(my_documents_test,list(dictionary=colnames(DTM_train)))


X_test = as.matrix(DTM_test)
```

```{r}
#Naive Bayes

predictions = NULL
for (i in 1:nrow(X_test)) {
  # get maximum Naive Bayes log probabilities
  max = -(Inf)
  author = NULL
  for (j in 1:nrow(w_all)) {
    result = sum(w_all[j,]*X_test[i,])
    if (result > max) {
      max = result
      author = rownames(w_all)[j]
    }
  }
  predictions = append(predictions, author)
}

predict_results = table(test_labels,predictions) #FIX: needs to be 50x50, returning 50x20 currently
```

```{r}
correct = NULL
for (i in 1:nrow(predict_results)) {
  correct = append(correct, predict_results[i,i])
}

correct_by_author = data.frame(correct, row.names = author_names)
correct_by_author
sum(correct_by_author)/2500
```

```{r}
#Random Forest

library(randomForest)
rf.fit = randomForest(x = X_train, y = as.factor(labels), mtry=6, ntree=200)
rf.pred = predict(rf.fit, data=X_test)
rf_results = table(test_labels, rf.pred)
rf_correct = NULL
for (i in 1:nrow(rf_results)) {
  rf_correct = append(rf_correct, rf_results[i, i])
}

rf_correct_by_author = data.frame(rf_correct, row.names = author_names)
rf_correct_by_author
sum(rf_correct_by_author)/2500
```

NEED TO SET SEED AND UPDATE THIS Random forest had 88.4% accuracy. It predicted worst for the author Scott Hills, where the model only predicted 24 correct (less than 50% correct). However, the model predicted 50 or close to 50 for many authors such as Jim Gilchrist, John Mastrini, and Jonathan Birt. Overall Random forest performed well on this data. 


###Practice with Association Rule Mining
```{r}
library(arules)
library(arulesViz)

groceries = read.transactions("/Users/hopeknopf/Desktop/STA 380 part 2/groceries.txt", format = 'basket', sep = ',')
summary(groceries)

groceries_rules = apriori(groceries, parameter=list(support=.005, confidence=.5, maxlen=8))
inspect(groceries_rules)

inspect(subset(groceries_rules, subset=lift > 3))
inspect(subset(groceries_rules, subset=confidence > 0.6))
inspect(subset(groceries_rules, subset=lift > 3 & confidence > 0.6))

plot(groceries_rules)
```

A lot of the item sets are very similar products grouped together, like citrus fruit and tropical fruit or root vegetables and other vegetables. The highest lift values were primarily sets of items that inform the purchase of 'other vegetables.'  We chose a threshhold for lift of 3, because most of the lift values ranged from 1-3, so the values with lift >3 showed us the highly informative baskets.  Most of the confidence values ranged from 0.5-0.7 so we chose a threshhold of confidence > 0.6.  The rules we found made sense, and primarily tell us about what groups of items tell us about the liklihood of buying whole milk and vegetables.  